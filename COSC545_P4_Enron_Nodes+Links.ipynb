{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460cb557-3932-4ae3-a758-e039d9497816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...5,000 files scanned; 2,872 nodes; 6,099 edges so far\n",
      "...10,000 files scanned; 5,776 nodes; 12,172 edges so far\n",
      "...15,000 files scanned; 8,066 nodes; 18,900 edges so far\n",
      "...20,000 files scanned; 10,814 nodes; 26,530 edges so far\n",
      "...25,000 files scanned; 13,282 nodes; 36,986 edges so far\n",
      "...30,000 files scanned; 16,193 nodes; 53,446 edges so far\n",
      "...35,000 files scanned; 18,409 nodes; 62,737 edges so far\n",
      "...40,000 files scanned; 20,193 nodes; 75,535 edges so far\n",
      "...45,000 files scanned; 22,239 nodes; 84,690 edges so far\n",
      "...50,000 files scanned; 24,906 nodes; 90,881 edges so far\n",
      "...55,000 files scanned; 26,072 nodes; 98,045 edges so far\n",
      "...60,000 files scanned; 28,076 nodes; 108,213 edges so far\n",
      "...65,000 files scanned; 29,056 nodes; 115,583 edges so far\n",
      "...70,000 files scanned; 29,468 nodes; 118,440 edges so far\n",
      "...75,000 files scanned; 30,245 nodes; 121,781 edges so far\n",
      "...80,000 files scanned; 31,615 nodes; 125,651 edges so far\n",
      "...85,000 files scanned; 32,160 nodes; 129,262 edges so far\n",
      "...90,000 files scanned; 32,841 nodes; 132,440 edges so far\n",
      "...95,000 files scanned; 35,025 nodes; 145,878 edges so far\n",
      "...100,000 files scanned; 37,651 nodes; 153,290 edges so far\n",
      "...105,000 files scanned; 39,535 nodes; 160,130 edges so far\n",
      "...110,000 files scanned; 40,614 nodes; 164,927 edges so far\n",
      "...115,000 files scanned; 41,853 nodes; 170,274 edges so far\n",
      "...120,000 files scanned; 43,260 nodes; 177,848 edges so far\n",
      "...125,000 files scanned; 46,295 nodes; 186,912 edges so far\n",
      "Done. Scanned 128,103 files.\n",
      "Unique nodes: 46,848\n",
      "Unique directed edges: 188,444\n",
      "Wrote nodes to: /Users/alinaharrison-trent/Downloads/enron_nodes.csv\n",
      "Wrote edges to: /Users/alinaharrison-trent/Downloads/enron_edges.csv\n"
     ]
    }
   ],
   "source": [
    "#AHT Note: This implementation expects enron dataset stored locally. For me, this was in my home /Downloads path\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from email.parser import BytesParser\n",
    "from email import policy\n",
    "from email.utils import getaddresses\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Path Configuration\n",
    "BASE_DIR = Path.home() / \"Downloads\" / \"Enron\"\n",
    "INCLUDE_HEADERS = (\"From\", \"To\", \"Cc\", \"Bcc\")\n",
    "WRITE_DIR = Path.home() / \"Downloads\"\n",
    "NODES_CSV = WRITE_DIR / \"enron_nodes.csv\"\n",
    "EDGES_CSV = WRITE_DIR / \"enron_edges.csv\"\n",
    "UNDIRECTED = False\n",
    "\n",
    "\n",
    "def normalize_email(addr: str) -> str | None:\n",
    "    if not addr:\n",
    "        return None\n",
    "    addr = addr.strip().lower()\n",
    "    if \"@\" not in addr:\n",
    "        return None\n",
    "    return addr\n",
    "\n",
    "def parse_headers(fp: Path):\n",
    "    try:\n",
    "        with fp.open(\"rb\") as f:\n",
    "            msg = BytesParser(policy=policy.default).parse(f, headersonly=True)\n",
    "    except Exception:\n",
    "        return None, set()\n",
    "\n",
    "    # from address, take first valid one\n",
    "    from_addrs = [normalize_email(a) for _, a in getaddresses([msg.get(\"From\", \"\")])]\n",
    "    from_addr = next((a for a in from_addrs if a), None)\n",
    "\n",
    "    # recipients, from To/Cc/Bcc configurable\n",
    "    recips = set()\n",
    "    for h in INCLUDE_HEADERS:\n",
    "        if h == \"From\":\n",
    "            continue\n",
    "        pairs = getaddresses([msg.get(h, \"\")])\n",
    "        for _, a in pairs:\n",
    "            na = normalize_email(a)\n",
    "            if na:\n",
    "                recips.add(na)\n",
    "\n",
    "    # remove self-loops, if any\n",
    "    if from_addr in recips:\n",
    "        recips.discard(from_addr)\n",
    "\n",
    "    return from_addr, recips\n",
    "\n",
    "def iter_all_document_files(base_dir: Path):\n",
    "    if not base_dir.exists():\n",
    "        raise FileNotFoundError(f\"Base directory not found: {base_dir}\")\n",
    "    for all_docs_dir in base_dir.glob(\"*/all_documents\"):\n",
    "        if all_docs_dir.is_dir():\n",
    "            for fp in all_docs_dir.rglob(\"*\"):\n",
    "                if fp.is_file():\n",
    "                    yield fp\n",
    "\n",
    "def build_graph(base_dir: Path):\n",
    "    nodes = set()\n",
    "    edges = Counter()\n",
    "    total_files = 0\n",
    "\n",
    "    for fp in iter_all_document_files(base_dir):\n",
    "        total_files += 1\n",
    "        from_addr, recips = parse_headers(fp)\n",
    "\n",
    "        if from_addr:\n",
    "            nodes.add(from_addr)\n",
    "        nodes.update(recips)\n",
    "\n",
    "        if from_addr and recips:\n",
    "            if UNDIRECTED:\n",
    "                for r in recips:\n",
    "                    a, b = sorted([from_addr, r])\n",
    "                    edges[(a, b)] += 1\n",
    "            else:\n",
    "                for r in recips:\n",
    "                    edges[(from_addr, r)] += 1\n",
    "\n",
    "        if total_files % 5000 == 0:\n",
    "            print(f\"...{total_files:,} files scanned; \"\n",
    "                  f\"{len(nodes):,} nodes; {len(edges):,} edges so far\")\n",
    "\n",
    "    print(f\"Done. Scanned {total_files:,} files.\")\n",
    "    print(f\"Unique nodes: {len(nodes):,}\")\n",
    "    print(f\"Unique {'undirected' if UNDIRECTED else 'directed'} edges: {len(edges):,}\")\n",
    "    return nodes, edges\n",
    "\n",
    "def write_nodes_csv(nodes: set[str], path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"email\"])\n",
    "        for addr in sorted(nodes):\n",
    "            w.writerow([addr])\n",
    "    print(f\"Wrote nodes to: {path}\")\n",
    "\n",
    "def write_edges_csv(edges: Counter, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"source\", \"target\", \"weight\"])\n",
    "        for (src, dst), wt in edges.items():\n",
    "            w.writerow([src, dst, wt])\n",
    "    print(f\"Wrote edges to: {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nodes, edges = build_graph(BASE_DIR)\n",
    "    write_nodes_csv(nodes, NODES_CSV)\n",
    "    write_edges_csv(edges, EDGES_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9125bec-2b12-4800-9587-cc3c6cdede6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
